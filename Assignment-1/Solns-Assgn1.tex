\documentclass{article}
\usepackage[margin=1in]{geometry}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{listings}

\title{Solutions to the Assignment - 1 : CS5480 - \\
Deep Learning}
\author{Vishwak Srinivasan\\
\texttt{CS15BTECH11043}}
\date{}

\begin{document}
\maketitle

\section*{Question 1}

\subsection*{Part a}
\begin{flushleft}
Method 1:
\begin{lstlisting}[language=Python]
t = torch.Tensor([[1, 2, 3],[4, 5, 6],[7, 8, 9]])
col = t[:,1]
print(col)  # Will print a torch.Tensor of size 3
\end{lstlisting}

Method 2:
\begin{lstlisting}[language=Python]
t = torch.Tensor([[1, 2, 3],[4, 5, 6],[7, 8, 9]])
col = t.view(-1)[1::3]
print(col)  # Will print a torch.Tensor of size 3
\end{lstlisting}

Method 3:
\begin{lstlisting}[language=Python]
t = torch.Tensor([[1, 2, 3],[4, 5, 6],[7, 8, 9]])
col = t.mm(torch.Tensor([0, 1, 0]).view(-1)).view(-1)
print(col)  # Will print a torch.Tensor of size 3
\end{lstlisting}
\end{flushleft}

\subsection*{Part b}
\begin{flushleft}
\begin{itemize}
\item \texttt{Tensor}: A wrapper for storing data. With \texttt{Tensor}s, you can perform operations like arithmetic operations, logical operations, exponentiation and so on. A \texttt{Tensor} cannot be differentiated i.e., is never a part of the \texttt{autograd} graph. \texttt{Tensor}s can be multi-dimensional.
\item \texttt{Variable}: A wrapper around \texttt{Tensor}. By default, the \texttt{requires\_grad} attribute is set to \texttt{false}, which means that the derivatives are not calculated for this variable in the graph. Setting \texttt{requires\_grad} attribute to \texttt{true} allows differentiation w.r.t. to this value's position in the \texttt{autograd} graph. Supports almost all operations as \texttt{Tensor}s, except a few.
\item \texttt{Storage}: A data wrapper. It is a one-dimensional \emph{contiguous} set of data in memory. Typically, a \texttt{Tensor} contains multiple of such \texttt{Storage} blocks.
\end{itemize}
\end{flushleft}

\end{document}
